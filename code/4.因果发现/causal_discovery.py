"""
å› æœå‘ç°æ¨¡å— v1.0ï¼šLiNGAM ç»“æ„å­¦ä¹  + DoWhy å› æœæ¨æ–­
==================================================

ç›®æ ‡ï¼š
1. å­¦ä¹ ç¯å¢ƒå‚æ•°ä¸ç—…å®³/æ­»äº¡ä¹‹é—´çš„å› æœç»“æ„ (DAG)
2. ä¼°è®¡å…³é”®å¹²é¢„ï¼ˆå¦‚ï¼šå¢åŠ å…‰ç…§ã€æé«˜æº¶æ°§ï¼‰çš„å› æœæ•ˆåº” (ATE)

æ–¹æ³•ï¼š
1. æ•°æ®é¢„å¤„ç†ï¼šé€‰æ‹©å…³é”®å˜é‡ï¼Œå¤„ç†ç¼ºå¤±å€¼ï¼Œæ ‡å‡†åŒ–
2. ç»“æ„å­¦ä¹ ï¼šä½¿ç”¨ DirectLiNGAM ç®—æ³•å­¦ä¹ å˜é‡é—´çš„å› æœé¡ºåºå’Œè¿æ¥å¼ºåº¦
3. å› æœå›¾å¯è§†åŒ–ï¼šç”Ÿæˆ DAG å›¾
4. å› æœæ•ˆåº”ä¼°è®¡ï¼šä½¿ç”¨ DoWhy åŸºäºå­¦ä¹ åˆ°çš„å›¾è¿›è¡Œå¹²é¢„ä¼°è®¡
   - çº¿æ€§å›å½’ä¼°ç®—å™¨
   - å€¾å‘æ€§å¾—åˆ†åŒ¹é… (PSM) éªŒè¯
   - å®‰æ…°å‰‚æ£€éªŒ (Placebo Refutation)

è¾“å‡ºï¼šoutput/
"""

import sys
import warnings
import json
from pathlib import Path
from datetime import datetime

import numpy as np
import pandas as pd
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns
import networkx as nx

import lingam
from lingam.utils import make_dot
import dowhy
from dowhy import CausalModel

# ============================================================
# è·¯å¾„é…ç½®
# ============================================================
SCRIPT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SCRIPT_DIR.parent.parent
DATA_DIR = PROJECT_ROOT / "data"
OUTPUT_DIR = SCRIPT_DIR / "output"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

FEATURED_HONGGUANG = DATA_DIR / "featured_çº¢å…‰.csv"
FEATURED_KAZUO = DATA_DIR / "featured_å–€å·¦.csv"

# éšæœºç§å­
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)

warnings.filterwarnings("ignore")

# ============================================================
# å˜é‡é€‰æ‹©
# ============================================================
# æˆ‘ä»¬ä¸ä½¿ç”¨æ‰€æœ‰70+ä¸ªç‰¹å¾ï¼Œè€Œæ˜¯é€‰æ‹©å…·æœ‰ç‰©ç†ä»£è¡¨æ€§çš„å…³é”®å˜é‡
CAUSAL_VARS = [
    # ç¯å¢ƒå› å­ (Causes)
    "å…‰ç…§æ—¶é•¿h", "å…‰ç…§_å³°å€¼",
    "æ°´æ¸©_æ—¥å‡", "æ°´æ¸©_æ—¥è¾ƒå·®",
    "æº¶æ°§mg/L", "æ°¨æ°®mg/L",
    "PH", "ECå€¼ms/cm",
    "æ°”æ¸©_æ—¥å‡", "æ°”æ¸©_æ—¥è¾ƒå·®",
    "æ¹¿åº¦_æ—¥å‡",
    
    # ç»“æœ (Effects)
    "è”¬èœ_ç—…å®³æ¬¡æ•°",
    "é±¼_æ­»äº¡æ•°é‡",
]

# å˜é‡é‡å‘½åï¼ˆç®€åŒ–å›¾æ˜¾ç¤ºï¼‰
VAR_RENAME = {
    "å…‰ç…§æ—¶é•¿h": "Light_Hours",
    "å…‰ç…§_å³°å€¼": "Light_Peak",
    "æ°´æ¸©_æ—¥å‡": "Water_Temp",
    "æ°´æ¸©_æ—¥è¾ƒå·®": "Water_Temp_Diff",
    "æº¶æ°§mg/L": "DO",
    "æ°¨æ°®mg/L": "Ammonia",
    "PH": "PH",
    "ECå€¼ms/cm": "EC",
    "æ°”æ¸©_æ—¥å‡": "Air_Temp",
    "æ°”æ¸©_æ—¥è¾ƒå·®": "Air_Temp_Diff",
    "æ¹¿åº¦_æ—¥å‡": "Humidity",
    "è”¬èœ_ç—…å®³æ¬¡æ•°": "Veg_Disease",
    "é±¼_æ­»äº¡æ•°é‡": "Fish_Death",
}

# åå‘æ˜ å°„
VAR_RENAME_INV = {v: k for k, v in VAR_RENAME.items()}


# ============================================================
# ä¸­æ–‡å­—ä½“
# ============================================================
def setup_chinese_font():
    for fp in ["/System/Library/Fonts/STHeiti Light.ttc",
               "/System/Library/Fonts/PingFang.ttc",
               "/System/Library/Fonts/Supplemental/Songti.ttc",
               "/System/Library/Fonts/Hiragino Sans GB.ttc"]:
        try:
            fm.fontManager.addfont(fp)
            prop = fm.FontProperties(fname=fp)
            plt.rcParams["font.family"] = prop.get_name()
            plt.rcParams["axes.unicode_minus"] = False
            return
        except Exception:
            continue
    plt.rcParams["font.sans-serif"] = ["Arial Unicode MS", "SimHei", "DejaVu Sans"]
    plt.rcParams["axes.unicode_minus"] = False

setup_chinese_font()


# ============================================================
# æ•°æ®å‡†å¤‡
# ============================================================
def load_and_preprocess(site="çº¢å…‰"):
    path = FEATURED_HONGGUANG if site == "çº¢å…‰" else FEATURED_KAZUO
    df = pd.read_csv(path)
    
    # é€‰æ‹©å˜é‡
    available_vars = [v for v in CAUSAL_VARS if v in df.columns]
    
    # å¡«å……ç¼ºå¤±å€¼ï¼ˆå› æœå‘ç°å¯¹ç¼ºå¤±å€¼æ•æ„Ÿï¼Œç®€å•æ’å€¼ï¼‰
    # æ°¨æ°®/æº¶æ°§å¯èƒ½æœ‰è¾ƒå¤šç¼ºå¤±ï¼Œç”¨æ—¶åºæ’å€¼
    df_subset = df[available_vars].copy()
    df_subset = df_subset.interpolate(method="linear").bfill().ffill()
    df_subset = df_subset.fillna(df_subset.mean()) # æœ€åçš„å…œåº•
    
    # é‡å‘½ååˆ—
    df_subset = df_subset.rename(columns=VAR_RENAME)
    
    print(f"ğŸ“Š [{site}] åŠ è½½æ•°æ®: {df_subset.shape}")
    print(f"   å˜é‡: {list(df_subset.columns)}")
    
    return df_subset


# ============================================================
# ç»“æ„å­¦ä¹  (LiNGAM)
# ============================================================
def learn_structure(df, site):
    print(f"\nğŸ§  [{site}] æ­£åœ¨å­¦ä¹ å› æœç»“æ„ (DirectLiNGAM)...")
    
    # æŠ½æ ·åŠ é€Ÿç»“æ„å­¦ä¹  (n=1000)
    if len(df) > 1000:
        print(f"   âš ï¸ æ•°æ®é‡è¾ƒå¤§ ({len(df)}), æŠ½æ · 1000 ç”¨äºç»“æ„å­¦ä¹ ...")
        df_train = df.sample(1000, random_state=RANDOM_SEED)
    else:
        df_train = df

    # DirectLiNGAM (ä½¿ç”¨ pwling ç†µæµ‹åº¦åŠ é€Ÿ)
    model = lingam.DirectLiNGAM(random_state=RANDOM_SEED, measure='pwling')
    model.fit(df_train)
    
    # é‚»æ¥çŸ©é˜µ (Adjacency Matrix) B
    # x_i = sum(b_ij * x_j) + e_i
    adj_matrix = model.adjacency_matrix_
    
    # å˜é‡é¡ºåº
    causal_order = model.causal_order_
    print("   å› æœé¡ºåº:", [df.columns[i] for i in causal_order])
    
    # å¯è§†åŒ–å› æœå›¾
    save_causal_graph(adj_matrix, df.columns, site)
    
    # è½¬ä¸º NetworkX å›¾ï¼ˆä¾› DoWhy ä½¿ç”¨ï¼‰
    G = nx.DiGraph()
    G.add_nodes_from(df.columns)
    print(f"   ğŸ•¸ï¸ å‘ç°çš„å› æœè¾¹ (é˜ˆå€¼ > 0.01):")
    for i, j in zip(*np.where(np.abs(adj_matrix) > 0.01)): # é˜ˆå€¼è¿‡æ»¤å¼±è¿æ¥
        weight = float(adj_matrix[i, j])
        if np.isnan(weight) or np.isinf(weight):
            continue
        target = df.columns[i]
        source = df.columns[j]
        print(f"      {source} -> {target} (w={weight:.4f})")
        G.add_edge(source, target, weight=weight)
        
    return model, G, adj_matrix


import shutil

def save_causal_graph(adj_matrix, labels, site):
    # ä½¿ç”¨ LiNGAM å†…ç½®ç»˜å›¾
    try:
        if shutil.which("dot") is None:
            print(f"   âš ï¸ æœªæ‰¾åˆ° 'dot' å‘½ä»¤ (Graphviz)ï¼Œè·³è¿‡å› æœå›¾ç»˜åˆ¶")
        else:
            dot = make_dot(adj_matrix, labels=labels.tolist())
            dot_path = OUTPUT_DIR / f"causal_graph_{site}"
            dot.render(dot_path, format="png", cleanup=True)
            print(f"   ğŸ–¼ï¸ å› æœå›¾å·²ä¿å­˜: {dot_path}.png")
    except Exception as e:
        print(f"   âš ï¸ ç»˜åˆ¶å› æœå›¾å¤±è´¥: {e}")
    
    # ç»˜åˆ¶çƒ­åŠ›å›¾çŸ©é˜µ
    plt.figure(figsize=(12, 10))
    sns.heatmap(adj_matrix, annot=True, fmt=".2f", cmap="vlag", center=0,
                xticklabels=labels, yticklabels=labels)
    plt.title(f"å› æœè¿æ¥å¼ºåº¦çŸ©é˜µ ({site})\n(Col -> Row)")
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / f"adjacency_matrix_{site}.png", dpi=150)
    plt.close()


# ============================================================
# DoWhy å› æœæ•ˆåº”ä¼°è®¡
# ============================================================
def estimate_effect_dowhy(df, G, treatment, outcome, site):
    if treatment not in df.columns or outcome not in df.columns:
        print(f"   âš ï¸ è·³è¿‡: {treatment} -> {outcome} (å˜é‡ä¸å­˜åœ¨)")
        return None
        
    print(f"\nğŸ” [{site}] ä¼°è®¡å› æœæ•ˆåº”: {treatment} -> {outcome}")
    
    # å°† NetworkX å›¾è½¬ä¸º GML å­—ç¬¦ä¸² (DoWhy éœ€è¦)
    gml_str = "".join(nx.generate_gml(G))
    
    # 1. å®šä¹‰å› æœæ¨¡å‹
    model = CausalModel(
        data=df,
        treatment=treatment,
        outcome=outcome,
        graph=gml_str,
        missing_nodes_as_confounders=False # æˆ‘ä»¬å‡è®¾ DAG æ˜¯å®Œæ•´çš„ï¼ˆåŸºäº LiNGAMï¼‰
    )
    
    # 2. è¯†åˆ«å› æœæ•ˆåº” (Identification)
    identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)
    # print(identified_estimand) # debug
    
    # 3. ä¼°è®¡å› æœæ•ˆåº” (Estimation)
    # ä½¿ç”¨çº¿æ€§å›å½’
    estimate = model.estimate_effect(
        identified_estimand,
        method_name="backdoor.linear_regression",
        test_significance=True
    )
    
    print(f"   ğŸ¯ å› æœæ•ˆåº” (ATE): {estimate.value:.4f}")
    
    p_value = 1.0
    try:
        p_val_res = estimate.test_stat_significance()
        if p_val_res:
            p_value = p_val_res.get('p_value', 1.0)
            # handle array p-value
            if isinstance(p_value, (np.ndarray, list)):
                p_value = p_value[0] if len(p_value) > 0 else 1.0
            print(f"      p-value: {float(p_value):.4f}")
    except Exception as e:
        print(f"      âš ï¸ æ— æ³•è·å– p-value: {e}")

    # 4. åé©³/éªŒè¯ (Refutation)
    placebo_p = 1.0
    subset_ATE = estimate.value
    
    try:
        # å®‰æ…°å‰‚å¹²é¢„ (Placebo Treatment)
        refute = model.refute_estimate(
            identified_estimand, estimate,
            method_name="placebo_treatment_refuter"
        )
        placebo_p = refute.refutation_result.get('p_value', 1.0)
        print(f"   ğŸ›¡ï¸ å®‰æ…°å‰‚æ£€éªŒ p-value: {placebo_p:.4f} (åº”è¯¥æ˜¯æ— å…³çš„)")
        
        # æ•°æ®å­é›†éªŒè¯
        refute_subset = model.refute_estimate(
            identified_estimand, estimate,
            method_name="data_subset_refuter",
            subset_fraction=0.8
        )
        subset_ATE = refute_subset.new_effect
        print(f"   ğŸ›¡ï¸ å­é›†éªŒè¯: æ–°ATE={subset_ATE:.4f} (åŸ={estimate.value:.4f})")
    except Exception as e:
        print(f"      âš ï¸ åé©³éªŒè¯å¤±è´¥: {e}")
    
    return {
        "treatment": treatment,
        "outcome": outcome,
        "ATE": estimate.value,
        "p_value": p_value,
        "placebo_p": placebo_p,
        "subset_ATE": subset_ATE,
        "is_robust": (p_value < 0.05) and \
                     (abs(estimate.value - subset_ATE) < abs(estimate.value) * 0.5 + 0.01)
    }


def get_expert_structure(df_columns):
    """
    å®šä¹‰åŸºäºé¢†åŸŸçŸ¥è¯†çš„ä¸“å®¶å› æœå›¾ (Physics-guided Causal Graph)
    é¿å… LiNGAM çº¯æ•°æ®é©±åŠ¨äº§ç”Ÿçš„åç›´è§‰æ–¹å‘ (å¦‚ ç—…å®³ -> å…‰ç…§)
    """
    G = nx.DiGraph()
    G.add_nodes_from(df_columns)
    
    # ç‰©ç†/ç”Ÿç‰©å­¦æœºåˆ¶è¾¹
    # 1. ç¯å¢ƒ -> è”¬èœç—…å®³
    if "Light_Hours" in df_columns and "Veg_Disease" in df_columns:
        G.add_edge("Light_Hours", "Veg_Disease") # å…‰ç…§å¢å¼ºæŠµæŠ—åŠ›
    if "Humidity" in df_columns and "Veg_Disease" in df_columns:
        G.add_edge("Humidity", "Veg_Disease")    # é«˜æ¹¿å¯¼è‡´ç—…å®³
    if "EC" in df_columns and "Veg_Disease" in df_columns:
        G.add_edge("EC", "Veg_Disease")
        
    # 2. ç¯å¢ƒ -> é±¼ç±»æ­»äº¡
    if "DO" in df_columns and "Fish_Death" in df_columns:
        G.add_edge("DO", "Fish_Death")           # ç¼ºæ°§ -> æ­»äº¡
    if "Ammonia" in df_columns and "Fish_Death" in df_columns:
        G.add_edge("Ammonia", "Fish_Death")      # æ°¨æ°®æ¯’æ€§
    if "Water_Temp_Diff" in df_columns and "Fish_Death" in df_columns:
        G.add_edge("Water_Temp_Diff", "Fish_Death") # æ¸©å·®åº”æ¿€
        
    # 3. ç¯å¢ƒé—´ç›¸äº’ä½œç”¨ (ç‰©ç†æœºåˆ¶)
    if "Water_Temp" in df_columns and "DO" in df_columns:
        G.add_edge("Water_Temp", "DO")           # æ¸©åº¦å½±å“é¥±å’Œæº¶æ°§
    if "Light_Hours" in df_columns and "DO" in df_columns:
        G.add_edge("Light_Hours", "DO")          # å…‰åˆä½œç”¨äº§æ°§
        
    return G

# ============================================================
# ä¸»æµç¨‹
# ============================================================
def main():
    print("=" * 60)
    print("  ğŸŒ³ å› æœå‘ç°ä¸æ¨ç† (LiNGAM + DoWhy)")
    print("=" * 60)
    print(f"  æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"  è¾“å‡º: {OUTPUT_DIR}")
    
    results = {}

    for site in ["çº¢å…‰", "å–€å·¦"]:
        print(f"\n\n{'='*40}")
        print(f"ğŸ“ ç«™ç‚¹: {site}")
        print(f"{'='*40}")
        
        # 1. å‡†å¤‡æ•°æ®
        df = load_and_preprocess(site)
        
        # 2. å­¦ä¹ ç»“æ„ (LiNGAM) - ä½œä¸ºå¯¹æ¯”
        lingam_model, G_lingam, adj_mat = learn_structure(df, site)
        
        # 3. æ„å»ºä¸“å®¶ç»“æ„ (Expert) - ä½œä¸ºä¸»è¦æ¨ç†ä¾æ®
        print(f"\nğŸ§  [{site}] æ„å»ºä¸“å®¶å› æœå›¾ (Physics-Guided)...")
        G_expert = get_expert_structure(df.columns)
        
        # ä¿å­˜ä¸“å®¶å›¾
        try:
            if shutil.which("dot"):
                dot = make_dot(nx.to_numpy_array(G_expert, nodelist=df.columns), labels=df.columns.tolist())
                dot.render(OUTPUT_DIR / f"causal_graph_expert_{site}", format="png", cleanup=True)
        except Exception: pass
        
        # å®šä¹‰æˆ‘ä»¬è¦æ¢ç©¶çš„å‡è®¾è·¯å¾„
        hypotheses = [
            ("Light_Hours", "Veg_Disease"),    # å…‰ç…§æ—¶é•¿ -> è”¬èœç—…å®³
            ("Water_Temp_Diff", "Fish_Death"), # æ°´æ¸©æ—¥è¾ƒå·® -> é±¼ç±»æ­»äº¡
            ("DO", "Fish_Death"),              # æº¶æ°§ -> é±¼ç±»æ­»äº¡
            ("Ammonia", "Fish_Death"),         # æ°¨æ°® -> é±¼ç±»æ­»äº¡
            ("EC", "Veg_Disease"),             # EC -> è”¬èœç—…å®³
            ("Humidity", "Veg_Disease"),       # æ¹¿åº¦ -> è”¬èœç—…å®³
        ]
        
        site_effects = []
        for treat, outcome in hypotheses:
            # ä¼˜å…ˆä½¿ç”¨ä¸“å®¶å›¾è¿›è¡Œä¼°è®¡ (å› ä¸º LiNGAM å‘ç°çš„æ–¹å‘å¾€å¾€æ˜¯åçš„)
            res = estimate_effect_dowhy(df, G_expert, treat, outcome, site)
            if res:
                site_effects.append(res)
        
        results[site] = site_effects
        
    # ä¿å­˜ç»“æœæŠ¥å‘Š
    report_path = OUTPUT_DIR / "causal_report.json"
    
    class NumpyEncoder(json.JSONEncoder):
        def default(self, obj):
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            if isinstance(obj, np.generic):
                return obj.item()
            return super(NumpyEncoder, self).default(obj)
            
    with open(report_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2, cls=NumpyEncoder)
        
    print(f"\nâœ… å®Œæˆ! æŠ¥å‘Šå·²ä¿å­˜è‡³ {report_path}")
    
    # æ‰“å°ç®€è¦æ€»ç»“
    print("\nğŸ“ ç»“æœæ‘˜è¦ (Robust Only):")
    for site, effects in results.items():
        print(f"\n  [{site}]")
        for eff in effects:
            if eff is None: continue
            star = "ğŸŒŸ" if eff["is_robust"] else "  "
            p_val = eff['p_value']
            # handle complex or array p-values
            if isinstance(p_val, (np.ndarray, list)):
                p_val = p_val[0] if len(p_val) > 0 else 1.0
            
            print(f"  {star} {eff['treatment']:15s} -> {eff['outcome']:15s} | "
                  f"ATE = {eff['ATE']:6.3f} (p={float(p_val):.3f})")

if __name__ == "__main__":
    main()
