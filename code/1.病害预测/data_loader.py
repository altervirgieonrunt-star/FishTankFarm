"""
æ•°æ®åŠ è½½ä¸é¢„å¤„ç†æ¨¡å—
- åŠ è½½ featured CSV
- æ‹†åˆ†ç‰¹å¾ / æ ‡ç­¾
- å¤„ç†ç¼ºå¤±å€¼
- äºŒå€¼åŒ–æ ‡ç­¾ï¼ˆæœ‰/æ— ç—…å®³ï¼‰
"""
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

from config import (
    FEATURED_HONGGUANG, FEATURED_KAZUO,
    AUGMENTED_HONGGUANG, AUGMENTED_KAZUO,
    EXCLUDE_COLS, RANDOM_SEED,
)


def load_featured(path, site_name: str = "") -> pd.DataFrame:
    """åŠ è½½ä¸€ä¸ª featured CSV æ–‡ä»¶"""
    df = pd.read_csv(path, parse_dates=["æ—¥æœŸ"])
    print(f"[{site_name}] åŠ è½½ {path.name}: {df.shape[0]} è¡Œ, {df.shape[1]} åˆ—")
    return df


def prepare_features_labels(df: pd.DataFrame, label_col: str):
    """
    ä» DataFrame ä¸­æ‹†åˆ†ç‰¹å¾å’Œæ ‡ç­¾ã€‚
    æ ‡ç­¾äºŒå€¼åŒ–ï¼š> 0 â†’ 1ï¼ˆæœ‰ç—…å®³/æ­»äº¡ï¼‰ï¼Œ= 0 â†’ 0ï¼ˆæ— ï¼‰

    Returns:
        X: ç‰¹å¾ DataFrame
        y: äºŒå€¼åŒ–æ ‡ç­¾ Series
        feature_names: ç‰¹å¾ååˆ—è¡¨
    """
    # æ’é™¤éç‰¹å¾åˆ—
    exclude = [c for c in EXCLUDE_COLS if c in df.columns]
    feature_cols = [c for c in df.columns if c not in exclude]
    
    X = df[feature_cols].copy()
    y = (df[label_col] > 0).astype(int)

    # å¤„ç†ç¼ºå¤±å€¼ï¼šç”¨è¯¥åˆ—ä¸­ä½æ•°å¡«å……
    for col in X.columns:
        if X[col].isnull().any():
            X[col] = X[col].fillna(X[col].median())

    # ç¡®ä¿æ²¡æœ‰ inf
    X = X.replace([np.inf, -np.inf], np.nan)
    for col in X.columns:
        if X[col].isnull().any():
            X[col] = X[col].fillna(0)

    print(f"  ç‰¹å¾æ•°: {X.shape[1]}, æ­£æ ·æœ¬: {y.sum()} ({y.mean()*100:.1f}%), "
          f"è´Ÿæ ·æœ¬: {(~y.astype(bool)).sum()} ({(1-y.mean())*100:.1f}%)")

    return X, y, list(X.columns)


def load_train_test(task_config: dict, use_augmented: bool = False):
    """
    åŠ è½½çº¢å…‰ï¼ˆè®­ç»ƒï¼‰å’Œå–€å·¦ï¼ˆæµ‹è¯•ï¼‰æ•°æ®

    Args:
        task_config: ä»»åŠ¡é…ç½® dictï¼ŒåŒ…å« label_col
        use_augmented: æ˜¯å¦ä½¿ç”¨å¢å¼ºæ•°æ®

    Returns:
        X_train, X_val, y_train, y_val: çº¢å…‰æ•°æ®çš„è®­ç»ƒ/éªŒè¯é›†
        X_test, y_test: å–€å·¦æ•°æ®ï¼ˆç‹¬ç«‹æµ‹è¯•é›†ï¼‰
        feature_names: ç‰¹å¾ååˆ—è¡¨
    """
    label_col = task_config["label_col"]

    # åŠ è½½æ•°æ®
    if use_augmented:
        df_hg = load_featured(AUGMENTED_HONGGUANG, "çº¢å…‰-å¢å¼º")
        # å¢å¼ºæ•°æ®å¯èƒ½æœ‰ _is_augmented åˆ—
        if "_is_augmented" in df_hg.columns:
            print(f"  å¢å¼ºæ•°æ®ä¸­çœŸå®æ ·æœ¬: {(~df_hg['_is_augmented']).sum()}, "
                  f"åˆæˆæ ·æœ¬: {df_hg['_is_augmented'].sum()}")
    else:
        df_hg = load_featured(FEATURED_HONGGUANG, "çº¢å…‰")

    df_kz = load_featured(FEATURED_KAZUO, "å–€å·¦")

    # å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾
    print("\nğŸ“Š çº¢å…‰æ•°æ®ï¼ˆè®­ç»ƒé›†ï¼‰:")
    X_hg, y_hg, feature_names = prepare_features_labels(df_hg, label_col)

    print("\nğŸ“Š å–€å·¦æ•°æ®ï¼ˆç‹¬ç«‹æµ‹è¯•é›†ï¼‰:")
    X_kz, y_kz, _ = prepare_features_labels(df_kz, label_col)

    # ç¡®ä¿å–€å·¦æ•°æ®å’Œçº¢å…‰æ•°æ®ä½¿ç”¨ç›¸åŒç‰¹å¾
    common_features = [f for f in feature_names if f in X_kz.columns]
    missing_in_kz = [f for f in feature_names if f not in X_kz.columns]
    if missing_in_kz:
        print(f"\n  âš ï¸ å–€å·¦æ•°æ®ç¼ºå°‘ {len(missing_in_kz)} ä¸ªç‰¹å¾: {missing_in_kz}")
        for f in missing_in_kz:
            X_kz[f] = 0

    X_hg = X_hg[feature_names]
    X_kz = X_kz[feature_names]

    # çº¢å…‰æ•°æ®æ‹†åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›† (80/20)
    X_train, X_val, y_train, y_val = train_test_split(
        X_hg, y_hg, test_size=0.2, random_state=RANDOM_SEED, stratify=y_hg
    )

    print(f"\nâœ… æ•°æ®å‡†å¤‡å®Œæˆ:")
    print(f"  è®­ç»ƒé›†: {X_train.shape[0]} è¡Œ")
    print(f"  éªŒè¯é›†: {X_val.shape[0]} è¡Œ")
    print(f"  ç‹¬ç«‹æµ‹è¯•é›† (å–€å·¦): {X_kz.shape[0]} è¡Œ")

    return X_train, X_val, y_train, y_val, X_kz, y_kz, feature_names


if __name__ == "__main__":
    from config import TASKS
    for task_name, task_cfg in TASKS.items():
        print(f"\n{'='*60}")
        print(f"ä»»åŠ¡: {task_name} â€” {task_cfg['description']}")
        print(f"{'='*60}")
        load_train_test(task_cfg, use_augmented=False)
