"""
Chronos-T5-Tiny æ—¶åºé¢„æµ‹ v2 â€” å¯¹ç­–æ”¹è¿›ç‰ˆ
æ”¹è¿›ç‚¹ï¼š
  1. context çª—å£ç¼©çŸ­è‡³ 48 å¤© â†’ æ°¨æ°®/pH å¯é¢„æµ‹
  2. ä½¿ç”¨æ¨¡å—çº§æ•°æ®ï¼ˆä¸æŒ‰æ—¥èšåˆï¼‰â†’ æ›´å¤šæ•°æ®ã€æ›´ç»†ç²’åº¦
  3. å¤šæ¨¡å—ç‹¬ç«‹é¢„æµ‹ + é›†æˆ â†’ æ›´é²æ£’çš„é¢„æµ‹
"""
import sys
import re
import json
import warnings
from pathlib import Path
from datetime import datetime

import numpy as np
import pandas as pd
import torch
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

warnings.filterwarnings("ignore")

# ============================================================
# è·¯å¾„
# ============================================================
SCRIPT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SCRIPT_DIR.parent.parent
DATA_DIR = PROJECT_ROOT / "data"
MODEL_DIR = SCRIPT_DIR / "models" / "chronos-t5-tiny"
OUTPUT_DIR = SCRIPT_DIR / "output2"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


def safe_filename(name: str) -> str:
    return re.sub(r'[/\\:*?"<>|]', '_', name)


# ============================================================
# æ”¹è¿›å‚æ•°
# ============================================================
TARGET_COLS = {
    "æ°´æ¸©_æ—¥å‡": {"unit": "â„ƒ", "description": "æ—¥å‡æ°´æ¸©"},
    "æº¶æ°§mg/L": {"unit": "mg/L", "description": "æº¶æ°§æµ“åº¦"},
    "æ°¨æ°®mg/L": {"unit": "mg/L", "description": "æ°¨æ°®æµ“åº¦"},
    "æ°”æ¸©_æ—¥å‡": {"unit": "â„ƒ", "description": "æ—¥å‡æ°”æ¸©"},
    "PH": {"unit": "", "description": "pHå€¼"},
}

CONTEXT_LENGTH = 48       # â† ç¼©çŸ­åˆ° 48 å¤©ï¼ˆåŸ128ï¼‰
PREDICTION_LENGTH = 14
NUM_SAMPLES = 50
MAX_MODULES = 5           # æ¯ä¸ªå˜é‡æœ€å¤šä½¿ç”¨å‰Nä¸ªæ•°æ®æœ€å¤šçš„æ¨¡å—


# ============================================================
# ä¸­æ–‡å­—ä½“
# ============================================================
def setup_chinese_font():
    for fp in ["/System/Library/Fonts/STHeiti Light.ttc",
               "/System/Library/Fonts/PingFang.ttc",
               "/System/Library/Fonts/Supplemental/Songti.ttc"]:
        try:
            fm.fontManager.addfont(fp)
            prop = fm.FontProperties(fname=fp)
            plt.rcParams["font.family"] = prop.get_name()
            plt.rcParams["axes.unicode_minus"] = False
            return
        except Exception:
            continue
    plt.rcParams["font.sans-serif"] = ["Arial Unicode MS", "SimHei"]
    plt.rcParams["axes.unicode_minus"] = False

setup_chinese_font()


# ============================================================
# åŠ è½½æ¨¡å—çº§æ•°æ®
# ============================================================
def load_module_data(site: str):
    """åŠ è½½æ¸…æ´—åæ•°æ®ï¼Œè¿”å›æŒ‰ (æ¨¡å—, æ—¥æœŸ) æ’åºçš„ DataFrame"""
    path = DATA_DIR / f"cleaned_{site}.csv"
    df = pd.read_csv(path, parse_dates=["æ—¥æœŸ"])
    df = df.sort_values(["æ¨¡å—", "æ—¥æœŸ"]).reset_index(drop=True)
    modules = df["æ¨¡å—"].nunique()
    print(f"ğŸ“Š [{site}] åŠ è½½: {len(df)} è¡Œ, {modules} ä¸ªæ¨¡å—")
    return df


def get_best_modules(df, col_name, n=MAX_MODULES):
    """æ‰¾å‡ºæŸä¸ªå˜é‡æœ‰æ•ˆæ•°æ®æœ€å¤šçš„ top-N æ¨¡å—"""
    valid = df.dropna(subset=[col_name])
    counts = valid.groupby("æ¨¡å—").size().sort_values(ascending=False)
    # åªé€‰æ•°æ®é‡ >= context + prediction çš„æ¨¡å—
    min_rows = CONTEXT_LENGTH + PREDICTION_LENGTH
    eligible = counts[counts >= min_rows]
    selected = eligible.head(n).index.tolist()
    return selected, counts


# ============================================================
# å•æ¨¡å—é¢„æµ‹
# ============================================================
def predict_module(pipeline, series: np.ndarray):
    """å¯¹ä¸€ä¸ªæ¨¡å—çš„æ—¶åºè¿›è¡Œé¢„æµ‹ï¼Œè¿”å› forecast array"""
    min_len = CONTEXT_LENGTH + PREDICTION_LENGTH
    if len(series) < min_len:
        return None, None

    context = series[-(CONTEXT_LENGTH + PREDICTION_LENGTH):-PREDICTION_LENGTH]
    actual = series[-PREDICTION_LENGTH:]
    context_tensor = torch.tensor(context, dtype=torch.float32)

    forecast = pipeline.predict(
        context_tensor,
        prediction_length=PREDICTION_LENGTH,
        num_samples=NUM_SAMPLES,
    )
    forecast_np = forecast.numpy().squeeze(0)  # (num_samples, pred_len)
    return forecast_np, actual


def compute_metrics(actual, median, low, high):
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
    mae = np.mean(np.abs(actual - median))
    rmse = np.sqrt(np.mean((actual - median) ** 2))
    mape = np.mean(np.abs((actual - median) / (np.abs(actual) + 1e-8))) * 100
    coverage = np.mean((actual >= low) & (actual <= high))
    return {"MAE": mae, "RMSE": rmse, "MAPE": mape, "Coverage_80": coverage}


# ============================================================
# å¤šæ¨¡å—é›†æˆé¢„æµ‹
# ============================================================
def ensemble_predict(pipeline, df, col_name, col_info, site):
    """
    å¯¹å¤šä¸ªæ¨¡å—ç‹¬ç«‹é¢„æµ‹åé›†æˆï¼š
    - æ¯ä¸ªæ¨¡å—ç‹¬ç«‹å¾—åˆ° forecast åˆ†å¸ƒ
    - å°†æ‰€æœ‰æ¨¡å—çš„ forecast samples åˆå¹¶
    - å–åˆå¹¶åˆ†å¸ƒçš„ä¸­ä½æ•°ä½œä¸ºæœ€ç»ˆé¢„æµ‹
    """
    selected_modules, all_counts = get_best_modules(df, col_name)

    if len(selected_modules) == 0:
        # å›é€€ï¼šå°è¯•æ—¥èšåˆ
        numeric = df.select_dtypes(include=[np.number]).columns.tolist()
        daily = df.groupby("æ—¥æœŸ")[numeric].mean().sort_index()
        series = daily[col_name].dropna().values
        if len(series) >= CONTEXT_LENGTH + PREDICTION_LENGTH:
            print(f"  ğŸ’¡ æ— æ¨¡å—æ»¡è¶³è¦æ±‚ï¼Œå›é€€åˆ°æ—¥èšåˆæ•°æ® ({len(series)} å¤©)")
            forecast_np, actual = predict_module(pipeline, series)
            if forecast_np is not None:
                median = np.median(forecast_np, axis=0)
                low = np.percentile(forecast_np, 10, axis=0)
                high = np.percentile(forecast_np, 90, axis=0)
                metrics = compute_metrics(actual, median, low, high)
                return {
                    "col_name": col_name, "unit": col_info["unit"],
                    "description": col_info["description"],
                    "actual": actual, "median": median,
                    "low_10": low, "high_90": high,
                    "n_modules": 0, "method": "æ—¥èšåˆå›é€€",
                    **metrics,
                }
        print(f"  âŒ {col_name}: æ•°æ®ä¸è¶³ï¼Œæ— æ³•é¢„æµ‹")
        return None

    print(f"  ğŸ“‹ é€‰å– {len(selected_modules)} ä¸ªæ¨¡å—: {selected_modules}")
    print(f"     å„æ¨¡å—æ•°æ®é‡: {[int(all_counts[m]) for m in selected_modules]}")

    all_forecasts = []
    actuals = []
    module_metrics = []

    for mod in selected_modules:
        mod_data = df[df["æ¨¡å—"] == mod].sort_values("æ—¥æœŸ")
        series = mod_data[col_name].dropna().values

        forecast_np, actual = predict_module(pipeline, series)
        if forecast_np is None:
            continue

        all_forecasts.append(forecast_np)
        actuals.append(actual)

        # å•æ¨¡å—æŒ‡æ ‡
        med = np.median(forecast_np, axis=0)
        lo = np.percentile(forecast_np, 10, axis=0)
        hi = np.percentile(forecast_np, 90, axis=0)
        m = compute_metrics(actual, med, lo, hi)
        module_metrics.append({"module": mod, **m})
        print(f"    {mod}: MAE={m['MAE']:.4f}, MAPE={m['MAPE']:.1f}%")

    if not all_forecasts:
        print(f"  âŒ {col_name}: æ‰€æœ‰æ¨¡å—é¢„æµ‹å¤±è´¥")
        return None

    # é›†æˆï¼šåˆå¹¶æ‰€æœ‰æ¨¡å—çš„ forecast samples
    # æ³¨æ„ï¼šä¸åŒæ¨¡å—çš„ actual å¯èƒ½ä¸åŒï¼ˆä¸åŒæ—¶é—´æ®µï¼‰ï¼Œ
    # æ‰€ä»¥æˆ‘ä»¬ç”¨ç¬¬ä¸€ä¸ªæ¨¡å—çš„ actual ä½œä¸ºå‚è€ƒï¼ˆæ—¶é—´æœ€è¿‘çš„æ•°æ®ï¼‰
    ensemble_forecast = np.concatenate(all_forecasts, axis=0)
    ref_actual = actuals[0]  # ä½¿ç”¨æ•°æ®æœ€å¤šçš„æ¨¡å—çš„ actual

    ensemble_median = np.median(ensemble_forecast, axis=0)
    ensemble_low = np.percentile(ensemble_forecast, 10, axis=0)
    ensemble_high = np.percentile(ensemble_forecast, 90, axis=0)
    ensemble_metrics = compute_metrics(ref_actual, ensemble_median, ensemble_low, ensemble_high)

    print(f"  ğŸ”— é›†æˆç»“æœ ({len(all_forecasts)} æ¨¡å—): "
          f"MAE={ensemble_metrics['MAE']:.4f}, RMSE={ensemble_metrics['RMSE']:.4f}, "
          f"MAPE={ensemble_metrics['MAPE']:.1f}%, Cov={ensemble_metrics['Coverage_80']:.0%}")

    # ä¹Ÿæä¾›è¿‘ context å¤©çš„å†å²æ•°æ®ç”¨äºç»˜å›¾
    best_mod = selected_modules[0]
    best_series = df[df["æ¨¡å—"] == best_mod].sort_values("æ—¥æœŸ")[col_name].dropna().values
    context_for_plot = best_series[-(CONTEXT_LENGTH + PREDICTION_LENGTH):-PREDICTION_LENGTH]

    return {
        "col_name": col_name,
        "unit": col_info["unit"],
        "description": col_info["description"],
        "context": context_for_plot,
        "actual": ref_actual,
        "median": ensemble_median,
        "low_10": ensemble_low,
        "high_90": ensemble_high,
        "n_modules": len(all_forecasts),
        "method": f"å¤šæ¨¡å—é›†æˆ({len(all_forecasts)}ä¸ª)",
        "module_metrics": module_metrics,
        **ensemble_metrics,
    }


# ============================================================
# å¯è§†åŒ–
# ============================================================
def plot_forecast(result, site):
    fig, ax = plt.subplots(figsize=(14, 5))
    col = result["col_name"]
    unit = result["unit"]
    n_pred = len(result["actual"])

    if "context" in result and result["context"] is not None:
        n_ctx = len(result["context"])
        ax.plot(range(n_ctx), result["context"], "b-", alpha=0.5, lw=1, label="å†å²æ•°æ®")
        pred_x = range(n_ctx, n_ctx + n_pred)
    else:
        n_ctx = 0
        pred_x = range(n_pred)

    ax.fill_between(pred_x, result["low_10"], result["high_90"],
                    alpha=0.2, color="orange", label="80%ç½®ä¿¡åŒºé—´")
    ax.plot(pred_x, result["median"], "r-", lw=2, label="é¢„æµ‹ä¸­ä½æ•°")
    ax.plot(pred_x, result["actual"], "g--", lw=2, marker="o", ms=4, label="çœŸå®å€¼")

    if n_ctx > 0:
        ax.axvline(x=n_ctx - 0.5, color="gray", ls="--", alpha=0.5)

    method = result.get("method", "")
    ax.set_title(
        f"{site} â€” {result['description']}ï¼ˆ{col}ï¼‰é¢„æµ‹ [{method}]\n"
        f"MAE={result['MAE']:.4f}{unit}  RMSE={result['RMSE']:.4f}{unit}  "
        f"MAPE={result['MAPE']:.1f}%  Coverage(80%)={result['Coverage_80']:.0%}",
        fontsize=11
    )
    ax.set_xlabel(f"å¤© (context={CONTEXT_LENGTH}å¤© â†’ é¢„æµ‹{PREDICTION_LENGTH}å¤©)")
    ax.set_ylabel(f"{col} ({unit})" if unit else col)
    ax.legend(loc="upper left")
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    fig_path = OUTPUT_DIR / f"forecast_{safe_filename(col)}_{site}.png"
    plt.savefig(fig_path, dpi=150, bbox_inches="tight")
    plt.close()
    return fig_path


def plot_summary(all_results, site):
    valid = {k: v for k, v in all_results.items() if v is not None}
    n = len(valid)
    if n == 0:
        return None

    fig, axes = plt.subplots(n, 1, figsize=(14, 4 * n))
    if n == 1:
        axes = [axes]

    for ax, (col_name, r) in zip(axes, valid.items()):
        n_pred = len(r["actual"])
        if "context" in r and r["context"] is not None:
            n_ctx = len(r["context"])
            ax.plot(range(n_ctx), r["context"], "b-", alpha=0.4, lw=1)
            pred_x = range(n_ctx, n_ctx + n_pred)
            ax.axvline(x=n_ctx - 0.5, color="gray", ls="--", alpha=0.5)
        else:
            pred_x = range(n_pred)

        ax.fill_between(pred_x, r["low_10"], r["high_90"], alpha=0.2, color="orange")
        ax.plot(pred_x, r["median"], "r-", lw=2, label="é¢„æµ‹")
        ax.plot(pred_x, r["actual"], "g--", lw=2, marker="o", ms=3, label="çœŸå®")
        ax.set_ylabel(f"{r['description']}\n({r['unit']})" if r['unit'] else r['description'])
        ax.set_title(f"{col_name} [{r.get('method','')}] | MAE={r['MAE']:.4f} "
                     f"RMSE={r['RMSE']:.4f} MAPE={r['MAPE']:.1f}% "
                     f"Cov={r['Coverage_80']:.0%}", fontsize=10)
        ax.legend(loc="upper left", fontsize=8)
        ax.grid(True, alpha=0.3)

    fig.suptitle(f"Chronos-T5-Tiny v2 é¢„æµ‹æ±‡æ€» â€” {site} (context={CONTEXT_LENGTH}å¤©, å¤šæ¨¡å—é›†æˆ)",
                 fontsize=13, fontweight="bold", y=1.01)
    plt.tight_layout()
    fig_path = OUTPUT_DIR / f"forecast_summary_{site}.png"
    plt.savefig(fig_path, dpi=150, bbox_inches="tight")
    plt.close()
    return fig_path


# ============================================================
# å¯¹æ¯”è¡¨: v1 vs v2
# ============================================================
def load_v1_metrics(site):
    """åŠ è½½ v1 çš„æŒ‡æ ‡ç”¨äºå¯¹æ¯”"""
    v1_path = SCRIPT_DIR / "output" / f"report_{site}.json"
    if v1_path.exists():
        with open(v1_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return {m["å˜é‡"]: m for m in data.get("æŒ‡æ ‡", [])}
    return {}


def print_comparison(v1_metrics, v2_results, site):
    """æ‰“å° v1 vs v2 å¯¹æ¯”è¡¨"""
    print(f"\n{'='*70}")
    print(f"ğŸ“Š v1 vs v2 å¯¹æ¯” â€” {site}")
    print(f"{'='*70}")
    print(f"{'å˜é‡':>12s} | {'v1 MAE':>8s} â†’ {'v2 MAE':>8s} | {'v1 MAPE':>8s} â†’ {'v2 MAPE':>8s} | {'æ”¹è¿›':>6s}")
    print("-" * 70)

    comparison = []
    for col_name, v2 in v2_results.items():
        if v2 is None:
            continue
        v1 = v1_metrics.get(col_name, {})
        v1_mae = v1.get("MAE", None)
        v1_mape = v1.get("MAPE(%)", None)
        v2_mae = v2["MAE"]
        v2_mape = v2["MAPE"]

        if v1_mae is not None:
            improve = ((v1_mae - v2_mae) / v1_mae * 100)
            print(f"{col_name:>12s} | {v1_mae:8.4f} â†’ {v2_mae:8.4f} | "
                  f"{v1_mape:7.1f}% â†’ {v2_mape:7.1f}% | {improve:+5.1f}%")
        else:
            print(f"{col_name:>12s} | {'N/A':>8s} â†’ {v2_mae:8.4f} | "
                  f"{'N/A':>8s} â†’ {v2_mape:7.1f}% | {'NEW':>6s}")

        comparison.append({
            "å˜é‡": col_name,
            "v1_MAE": v1_mae,
            "v2_MAE": float(v2_mae),
            "v1_MAPE": v1_mape,
            "v2_MAPE": float(v2_mape),
            "v2_Coverage": float(v2["Coverage_80"]),
            "æ–¹æ³•": v2.get("method", ""),
        })

    return comparison


# ============================================================
# ä¸»æµç¨‹
# ============================================================
def run(pipeline, site):
    print(f"\n{'='*60}")
    print(f"  ğŸ”® Chronos v2 â€” {site} (context={CONTEXT_LENGTH}å¤©, å¤šæ¨¡å—é›†æˆ)")
    print(f"{'='*60}\n")

    df = load_module_data(site)

    all_results = {}
    metrics_list = []

    for col_name, col_info in TARGET_COLS.items():
        print(f"\nğŸ“ˆ é¢„æµ‹: {col_name} ({col_info['description']})")
        result = ensemble_predict(pipeline, df, col_name, col_info, site)
        all_results[col_name] = result

        if result is not None:
            fig_path = plot_forecast(result, site)
            print(f"  ğŸ“Š å›¾è¡¨å·²ä¿å­˜: {fig_path}")
            metrics_list.append({
                "å˜é‡": col_name,
                "æè¿°": col_info["description"],
                "MAE": float(result["MAE"]),
                "RMSE": float(result["RMSE"]),
                "MAPE(%)": float(result["MAPE"]),
                "Coverage(80%)": float(result["Coverage_80"]),
                "æ–¹æ³•": result.get("method", ""),
                "æ¨¡å—æ•°": result.get("n_modules", 0),
            })

    # æ±‡æ€»å›¾
    summary_fig = plot_summary(all_results, site)
    if summary_fig:
        print(f"\nğŸ“Š æ±‡æ€»å›¾å·²ä¿å­˜: {summary_fig}")

    # v1 vs v2 å¯¹æ¯”
    v1_metrics = load_v1_metrics(site)
    comparison = print_comparison(v1_metrics, all_results, site)

    # ä¿å­˜æŠ¥å‘Š
    report = {
        "æ¨¡å‹": "chronos-t5-tiny",
        "ç‰ˆæœ¬": "v2 (å¯¹ç­–æ”¹è¿›ç‰ˆ)",
        "ç«™ç‚¹": site,
        "æ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "æ”¹è¿›ç‚¹": [
            f"context çª—å£: 128â†’{CONTEXT_LENGTH} å¤©",
            "ä½¿ç”¨æ¨¡å—çº§æ•°æ®ï¼ˆä¸èšåˆï¼‰",
            f"å¤šæ¨¡å—é›†æˆï¼ˆæœ€å¤š{MAX_MODULES}ä¸ªæ¨¡å—ï¼‰",
        ],
        "æŒ‡æ ‡": metrics_list,
        "v1_vs_v2": comparison,
    }
    report_path = OUTPUT_DIR / f"report_{site}.json"
    with open(report_path, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    df_metrics = pd.DataFrame(metrics_list)
    csv_path = OUTPUT_DIR / f"metrics_{site}.csv"
    df_metrics.to_csv(csv_path, index=False)

    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    return all_results, comparison


def main():
    from chronos import ChronosPipeline

    print("=" * 60)
    print("  ğŸ”® Chronos-T5-Tiny v2 â€” å¯¹ç­–æ”¹è¿›ç‰ˆ")
    print("=" * 60)
    print(f"  æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"  æ”¹è¿›: context {CONTEXT_LENGTH}å¤© + æ¨¡å—çº§æ•°æ® + å¤šæ¨¡å—é›†æˆ")
    print(f"  è¾“å‡º: {OUTPUT_DIR}\n")

    device = "mps" if torch.backends.mps.is_available() else "cpu"
    print(f"ğŸ”§ åŠ è½½æ¨¡å‹... (è®¾å¤‡: {device})")
    pipeline = ChronosPipeline.from_pretrained(
        str(MODEL_DIR), device_map=device, dtype=torch.float32,
    )
    print("   âœ… æ¨¡å‹åŠ è½½å®Œæˆ\n")

    all_comparisons = {}
    for site in ["çº¢å…‰", "å–€å·¦"]:
        _, comp = run(pipeline, site)
        all_comparisons[site] = comp

    # æ±‡æ€»å¯¹æ¯”ä¿å­˜
    with open(OUTPUT_DIR / "comparison_v1_vs_v2.json", "w", encoding="utf-8") as f:
        json.dump(all_comparisons, f, ensure_ascii=False, indent=2)

    print(f"\n\n{'='*60}")
    print(f"  âœ… v2 å…¨éƒ¨å®Œæˆï¼")
    print(f"{'='*60}")
    for p in sorted(OUTPUT_DIR.iterdir()):
        print(f"    {p.name:50s} ({p.stat().st_size/1024:.1f} KB)")


if __name__ == "__main__":
    main()
